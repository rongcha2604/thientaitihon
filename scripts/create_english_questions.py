#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script t·∫°o b·ªô ƒë·ªÅ ti·∫øng Anh l·ªõp 1 - 16 ch·∫∑ng th·ª≠ th√°ch
M·ªói ch·∫∑ng 10 c√¢u h·ªèi, gi·∫£i th√≠ch song ng·ªØ (Ti·∫øng Vi·ªát + English)
Ph√¢n b·ªï ƒë√°p √°n ƒë√∫ng c√¢n ƒë·ªëi (A, B, C, D)
"""

import json
import random
import sys
import codecs
from pathlib import Path
from collections import Counter

# Fix encoding cho Windows console
if sys.platform == 'win32':
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# ƒê·ªãnh nghƒ©a d·ªØ li·ªáu 16 units
UNITS_DATA = [
    {
        "unit": 1,
        "title": "Unit 1: In the school playground",
        "phonics": "Bb",
        "vocabulary": ["ball", "bike", "book"],
        "sentence_patterns": ["Hi, I'm Bill.", "Bye, Bill."],
        "answer_dist": [3, 3, 2, 2]  # 3A, 3B, 2C, 2D
    },
    {
        "unit": 2,
        "title": "Unit 2: In the dining room",
        "phonics": "Cc",
        "vocabulary": ["cake", "car", "cat", "cup"],
        "sentence_patterns": ["I have a car."],
        "answer_dist": [3, 3, 2, 2]
    },
    {
        "unit": 3,
        "title": "Unit 3: At the street market",
        "phonics": "Aa",
        "vocabulary": ["apple", "bag", "can", "hat"],
        "sentence_patterns": ["This is my bag."],
        "answer_dist": [3, 3, 2, 2]
    },
    {
        "unit": 4,
        "title": "Unit 4: In the bedroom",
        "phonics": "Dd",
        "vocabulary": ["desk", "dog", "door", "duck"],
        "sentence_patterns": ["This is a dog."],
        "answer_dist": [3, 3, 2, 2]
    },
    {
        "unit": 5,
        "title": "Unit 5: At the fish and chip shop",
        "phonics": "Ii",
        "vocabulary": ["chicken", "chips", "fish", "milk"],
        "sentence_patterns": ["I like milk."],
        "answer_dist": [2, 3, 3, 2]  # 2A, 3B, 3C, 2D
    },
    {
        "unit": 6,
        "title": "Unit 6: In the classroom",
        "phonics": "Ee",
        "vocabulary": ["bell", "pen", "pencil", "red"],
        "sentence_patterns": ["It's a red pen."],
        "answer_dist": [2, 3, 3, 2]
    },
    {
        "unit": 7,
        "title": "Unit 7: In the garden",
        "phonics": "Gg",
        "vocabulary": ["garden", "gate", "girl", "goat"],
        "sentence_patterns": ["There's a garden."],
        "answer_dist": [2, 3, 3, 2]
    },
    {
        "unit": 8,
        "title": "Unit 8: In the park",
        "phonics": "Hh",
        "vocabulary": ["hair", "hand", "head", "horse"],
        "sentence_patterns": ["Touch your hair."],
        "answer_dist": [2, 3, 3, 2]
    },
    {
        "unit": 9,
        "title": "Unit 9: In the shop",
        "phonics": "Oo",
        "vocabulary": ["clocks", "locks", "mops", "pots"],
        "sentence_patterns": ["How many clocks? Two."],
        "answer_dist": [3, 2, 3, 2]  # 3A, 2B, 3C, 2D
    },
    {
        "unit": 10,
        "title": "Unit 10: At the zoo",
        "phonics": "Mm",
        "vocabulary": ["mango", "monkey", "mother", "mouse"],
        "sentence_patterns": ["That's a monkey."],
        "answer_dist": [3, 2, 3, 2]
    },
    {
        "unit": 11,
        "title": "Unit 11: At the bus stop",
        "phonics": "Uu",
        "vocabulary": ["bus", "run", "sun", "truck"],
        "sentence_patterns": ["She's running.", "He's running."],
        "answer_dist": [3, 2, 3, 2]
    },
    {
        "unit": 12,
        "title": "Unit 12: At the lake",
        "phonics": "Ll",
        "vocabulary": ["lake", "leaf", "lemons"],
        "sentence_patterns": ["Look at the lemons."],
        "answer_dist": [3, 2, 3, 2]
    },
    {
        "unit": 13,
        "title": "Unit 13: In the school canteen",
        "phonics": "Nn",
        "vocabulary": ["bananas", "noodles", "nuts"],
        "sentence_patterns": ["She's having noodles."],
        "answer_dist": [2, 3, 2, 3]  # 2A, 3B, 2C, 3D
    },
    {
        "unit": 14,
        "title": "Unit 14: In the toy shop",
        "phonics": "Tt",
        "vocabulary": ["teddy bear", "tiger", "top", "turtle"],
        "sentence_patterns": ["I can see a tiger."],
        "answer_dist": [2, 3, 2, 3]
    },
    {
        "unit": 15,
        "title": "Unit 15: At the football match",
        "phonics": "Ff",
        "vocabulary": ["face", "father", "foot", "football"],
        "sentence_patterns": ["Point to your hand."],
        "answer_dist": [2, 3, 2, 3]
    },
    {
        "unit": 16,
        "title": "Unit 16: At home",
        "phonics": "Ww",
        "vocabulary": ["wash", "water", "window"],
        "sentence_patterns": ["How many windows can you see? I can see six."],
        "answer_dist": [2, 3, 2, 3]
    }
]

# B·∫£ng d·ªãch c√¢u sang ti·∫øng Vi·ªát
SENTENCE_TRANSLATIONS = {
    "Hi, I'm Bill.": "Xin ch√†o, t√¥i l√† Bill.",
    "Bye, Bill.": "T·∫°m bi·ªát, Bill.",
    "I have a car.": "T√¥i c√≥ m·ªôt chi·∫øc xe h∆°i.",
    "This is my bag.": "ƒê√¢y l√† c·∫∑p c·ªßa t√¥i.",
    "This is a dog.": "ƒê√¢y l√† m·ªôt con ch√≥.",
    "I like milk.": "T√¥i th√≠ch s·ªØa.",
    "It's a red pen.": "ƒê√≥ l√† m·ªôt c√¢y b√∫t m√†u ƒë·ªè.",
    "There's a garden.": "C√≥ m·ªôt khu v∆∞·ªùn.",
    "Touch your hair.": "Ch·∫°m v√†o t√≥c c·ªßa b·∫°n.",
    "How many clocks? Two.": "C√≥ bao nhi√™u c√°i ƒë·ªìng h·ªì? Hai.",
    "That's a monkey.": "ƒê√≥ l√† m·ªôt con kh·ªâ.",
    "She's running.": "C√¥ ·∫•y ƒëang ch·∫°y.",
    "He's running.": "Anh ·∫•y ƒëang ch·∫°y.",
    "Look at the lemons.": "Nh√¨n v√†o nh·ªØng qu·∫£ chanh.",
    "She's having noodles.": "C√¥ ·∫•y ƒëang ƒÉn m√¨.",
    "I can see a tiger.": "T√¥i c√≥ th·ªÉ th·∫•y m·ªôt con h·ªï.",
    "Point to your hand.": "Ch·ªâ v√†o tay c·ªßa b·∫°n.",
    "How many windows can you see? I can see six.": "B·∫°n c√≥ th·ªÉ th·∫•y bao nhi√™u c·ª≠a s·ªï? T√¥i c√≥ th·ªÉ th·∫•y s√°u."
}

# T·∫•t c·∫£ t·ª´ v·ª±ng t·ª´ t·∫•t c·∫£ units (ƒë·ªÉ t·∫°o distractors)
ALL_VOCABULARY = []
for unit in UNITS_DATA:
    ALL_VOCABULARY.extend(unit["vocabulary"])

def get_distractor_words(correct_word, count=3, exclude_letter=None):
    """L·∫•y c√°c t·ª´ distractors (kh√°c v·ªõi t·ª´ ƒë√∫ng)"""
    distractors = []
    available_words = [w for w in ALL_VOCABULARY if w != correct_word]
    if exclude_letter:
        # Lo·∫°i b·ªè c√°c t·ª´ b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ c√°i exclude_letter
        available_words = [w for w in available_words if w[0].lower() != exclude_letter.lower()]
    random.shuffle(available_words)
    return available_words[:count]

def create_phonics_questions(unit_data):
    """T·∫°o c√¢u h·ªèi v·ªÅ Phonics (3-4 c√¢u)"""
    questions = []
    phonics = unit_data["phonics"]
    letter = phonics[0].upper()
    letter_lower = phonics[0].lower()
    
    # C√¢u 1: Nh·∫≠n bi·∫øt ch·ªØ c√°i
    other_letters = []
    for offset in [1, -1, 2, -2]:
        candidate = chr(ord(letter) + offset)
        if 'A' <= candidate <= 'Z' and candidate not in other_letters:
            other_letters.append(candidate)
            if len(other_letters) >= 3:
                break
    while len(other_letters) < 3:
        for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':
            if char != letter and char not in other_letters:
                other_letters.append(char)
                if len(other_letters) >= 3:
                    break
    
    options = [letter] + other_letters[:3]
    random.shuffle(options)
    correct_idx = options.index(letter)
    
    # T√™n ch·ªØ c√°i b·∫±ng ti·∫øng Vi·ªát
    letter_names_vn = {
        "A": "a", "B": "b√™", "C": "x√™", "D": "d√™", "E": "e", "F": "√©p", "G": "gi√™",
        "H": "h√°t", "I": "i", "J": "gi", "K": "ca", "L": "en-l·ªù", "M": "em-m·ªù",
        "N": "en-n·ªù", "O": "√¥", "P": "p√™", "Q": "quy", "R": "e-r·ªù", "S": "√©t-s√¨",
        "T": "t√™", "U": "u", "V": "v√™", "W": "ƒë·∫Øp-liu", "X": "√≠ch-x√¨", "Y": "i-c·ªù-r√©t", "Z": "d√©t"
    }
    letter_name_vn = letter_names_vn.get(letter, letter.lower())
    
    questions.append({
        "question": f"What letter is this: '{letter}'?",
        "options": options,
        "correct": correct_idx,
        "explanation": f"Ti·∫øng Vi·ªát: ƒê√¢y l√† ch·ªØ c√°i '{letter}' (ƒë·ªçc l√† '{letter_name_vn}'). English: This is the letter '{letter}'."
    })
    
    # C√¢u 2: T√¨m t·ª´ b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ c√°i (CH·ªà l·∫•y t·ª´ th·ª±c s·ª± b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ ƒë√≥)
    vocab_words_starting_with_letter = [w for w in unit_data["vocabulary"] if w[0].lower() == letter_lower]
    if vocab_words_starting_with_letter:
        vocab_word = vocab_words_starting_with_letter[0]
        distractors = get_distractor_words(vocab_word, 3, exclude_letter=letter_lower)
        options = [vocab_word] + distractors[:3]
        random.shuffle(options)
        correct_idx = options.index(vocab_word)
        
        questions.append({
            "question": f"Which word starts with '{letter}'?",
            "options": options,
            "correct": correct_idx,
            "explanation": f"Ti·∫øng Vi·ªát: T·ª´ '{vocab_word}' b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ '{letter}'. English: The word '{vocab_word}' starts with the letter '{letter}'."
        })
    
    # C√¢u 3: Ph√°t √¢m
    sound_map = {
        "Bb": "/b/", "Cc": "/k/", "Aa": "/√¶/", "Dd": "/d/",
        "Ii": "/…™/", "Ee": "/e/", "Gg": "/g/", "Hh": "/h/",
        "Oo": "/…í/", "Mm": "/m/", "Uu": "/ å/", "Ll": "/l/",
        "Nn": "/n/", "Tt": "/t/", "Ff": "/f/", "Ww": "/w/"
    }
    correct_sound = sound_map.get(phonics, "/?/")
    all_sounds = list(sound_map.values())
    other_sounds = [s for s in all_sounds if s != correct_sound]
    options = [correct_sound] + random.sample(other_sounds, 3)
    random.shuffle(options)
    correct_idx = options.index(correct_sound)
    
    questions.append({
        "question": f"How do you pronounce the letter '{letter}'?",
        "options": options,
        "correct": correct_idx,
        "explanation": f"Ti·∫øng Vi·ªát: Ch·ªØ '{letter}' ƒë∆∞·ª£c ph√°t √¢m l√† {correct_sound}. English: The letter '{letter}' is pronounced {correct_sound}."
    })
    
    return questions

def create_vocabulary_questions(unit_data):
    """T·∫°o c√¢u h·ªèi v·ªÅ Vocabulary (3-4 c√¢u)"""
    questions = []
    vocab_list = unit_data["vocabulary"]
    question_templates = [
        "What is the English word for this picture?",
        "Choose the correct word:",
        "Which word matches this?",
        "Select the right word:"
    ]
    
    used_templates = []
    for i, vocab_word in enumerate(vocab_list):
        # Ch·ªçn template kh√°c nhau cho m·ªói c√¢u
        template = question_templates[i % len(question_templates)]
        if template in used_templates:
            template = f"Choose the correct word: '{vocab_word}'"
        used_templates.append(template)
        
        distractors = get_distractor_words(vocab_word, 3)
        options = [vocab_word] + distractors[:3]
        random.shuffle(options)
        correct_idx = options.index(vocab_word)
        
        question_text = f"{template} {vocab_word}" if ":" in template else f"{template}"
        
        questions.append({
            "question": question_text,
            "options": options,
            "correct": correct_idx,
            "explanation": f"Ti·∫øng Vi·ªát: '{vocab_word}' l√† t·ª´ ti·∫øng Anh ƒë√∫ng. English: '{vocab_word}' is the correct English word."
        })
    
    return questions

def create_sentence_questions(unit_data):
    """T·∫°o c√¢u h·ªèi v·ªÅ Sentence patterns (2-3 c√¢u)"""
    questions = []
    sentences = unit_data["sentence_patterns"]
    
    if not sentences:
        return questions
    
    # C√¢u 1: Ho√†n th√†nh c√¢u
    sentence = sentences[0]
    # X·ª≠ l√Ω c√¢u c√≥ d·∫•u "?" (nh∆∞ "How many windows can you see? I can see six." ho·∫∑c "How many clocks? Two.")
    if "?" in sentence:
        # T√°ch c√¢u th√†nh 2 ph·∫ßn: ph·∫ßn tr∆∞·ªõc "?" v√† ph·∫ßn sau
        parts = sentence.split("?")
        if len(parts) == 2:
            # Ph·∫ßn sau "?" l√† c√¢u th·ª© 2 (ho·∫∑c t·ª´ ƒë∆°n)
            second_part = parts[1].strip()
            words = second_part.replace(".", "").replace(",", "").split()
            if len(words) >= 2:
                # C√¢u d√†i: "How many windows can you see? I can see six."
                # Ch·ªçn t·ª´ cu·ªëi c·ªßa ph·∫ßn 2
                blank_word = words[-1]
                incomplete = parts[0] + "? " + " ".join(words[:-1]) + " _____."
            elif len(words) == 1:
                # C√¢u ng·∫Øn: "How many clocks? Two."
                blank_word = words[0]
                incomplete = parts[0] + "? _____."
            else:
                # Fallback: x·ª≠ l√Ω nh∆∞ c√¢u b√¨nh th∆∞·ªùng
                words = sentence.replace(".", "").replace(",", "").replace("?", "").split()
                blank_word = words[-1] if words else ""
                incomplete = " ".join(words[:-1]) + " _____" + ("." if "." in sentence else "?")
        else:
            # Kh√¥ng c√≥ "?", x·ª≠ l√Ω b√¨nh th∆∞·ªùng
            words = sentence.replace(".", "").replace(",", "").split()
            blank_word = words[-1]
            incomplete = " ".join(words[:-1]) + " _____."
    else:
        words = sentence.replace(".", "").replace(",", "").split()
        if len(words) >= 3:
            # Ch·ªçn t·ª´ cu·ªëi ƒë·ªÉ l√†m blank (th∆∞·ªùng l√† t·ª´ quan tr·ªçng)
            blank_word = words[-1]
            incomplete = " ".join(words[:-1]) + " _____."
        else:
            blank_word = ""
            incomplete = ""
    
    if blank_word and incomplete:
        
        # T·∫°o options t·ª´ vocabulary c·ªßa unit
        distractors = []
        for vocab in unit_data["vocabulary"]:
            if vocab.lower() != blank_word.lower() and vocab not in distractors:
                distractors.append(vocab)
                if len(distractors) >= 3:
                    break
        # N·∫øu thi·∫øu, l·∫•y t·ª´ units kh√°c
        while len(distractors) < 3:
            for vocab in ALL_VOCABULARY:
                if vocab.lower() != blank_word.lower() and vocab not in distractors:
                    distractors.append(vocab)
                    if len(distractors) >= 3:
                        break
        
        options = [blank_word] + distractors[:3]
        random.shuffle(options)
        correct_idx = options.index(blank_word)
        
        questions.append({
            "question": f"Complete the sentence: {incomplete}",
            "options": options,
            "correct": correct_idx,
            "explanation": f"Ti·∫øng Vi·ªát: C√¢u ho√†n ch·ªânh l√† '{sentence}'. English: The complete sentence is '{sentence}'."
        })
    
    # C√¢u 2: D·ªãch c√¢u (n·∫øu c√≥ c√¢u th·ª© 2, d√πng c√¢u th·ª© 2, kh√¥ng th√¨ d√πng c√¢u 1)
    if len(sentences) > 1:
        sentence = sentences[1]
    else:
        sentence = sentences[0]
    
    vietnamese = SENTENCE_TRANSLATIONS.get(sentence, f"D·ªãch: {sentence}")
    
    # L·∫•y c√°c c√¢u kh√°c l√†m distractors
    other_sentences = []
    for unit in UNITS_DATA:
        if unit["unit"] != unit_data["unit"] and unit["sentence_patterns"]:
            for s in unit["sentence_patterns"]:
                if s != sentence and s not in other_sentences:
                    other_sentences.append(s)
                    if len(other_sentences) >= 10:
                        break
        if len(other_sentences) >= 10:
            break
    
    options = [sentence] + random.sample(other_sentences, min(3, len(other_sentences)))
    random.shuffle(options)
    correct_idx = options.index(sentence)
    
    questions.append({
        "question": f"Which sentence means '{vietnamese}'?",
        "options": options,
        "correct": correct_idx,
        "explanation": f"Ti·∫øng Vi·ªát: '{sentence}' c√≥ nghƒ©a l√† '{vietnamese}'. English: '{sentence}' means '{vietnamese}'."
    })
    
    return questions

def assign_correct_answers(questions, answer_distribution):
    """Ph√¢n b·ªï ƒë√°p √°n ƒë√∫ng theo distribution v√† ƒë·ªïi ch·ªó options"""
    # T·∫°o list ƒë√°p √°n theo distribution
    target_answers = []
    for idx, count in enumerate(answer_distribution):
        target_answers.extend([idx] * count)
    
    # X√°o tr·ªôn ƒë·ªÉ tr√°nh li√™n ti·∫øp, nh∆∞ng ƒë·∫£m b·∫£o kh√¥ng c√≥ 2 c√¢u li√™n ti·∫øp c√πng ƒë√°p √°n
    max_attempts = 100
    for attempt in range(max_attempts):
        random.shuffle(target_answers)
        # Ki·ªÉm tra kh√¥ng c√≥ 2 c√¢u li√™n ti·∫øp c√πng ƒë√°p √°n
        consecutive = False
        for i in range(len(target_answers) - 1):
            if target_answers[i] == target_answers[i + 1]:
                consecutive = True
                break
        if not consecutive:
            break
    
    # G√°n ƒë√°p √°n ƒë√∫ng cho t·ª´ng c√¢u
    for i, question in enumerate(questions):
        target_answer = target_answers[i] if i < len(target_answers) else i % 4
        current_correct = question["correct"]
        
        # N·∫øu ƒë√°p √°n hi·ªán t·∫°i kh√°c target, ƒë·ªïi ch·ªó
        if current_correct != target_answer:
            # ƒê·ªïi ch·ªó options
            temp = question["options"][current_correct]
            question["options"][current_correct] = question["options"][target_answer]
            question["options"][target_answer] = temp
            question["correct"] = target_answer
    
    return questions

def create_week_file(unit_data, output_dir):
    """T·∫°o file JSON cho m·ªôt unit"""
    week_num = unit_data["unit"]
    
    # T·∫°o t·∫•t c·∫£ c√¢u h·ªèi
    all_questions = []
    
    # Phonics questions (3 c√¢u)
    phonics_questions = create_phonics_questions(unit_data)
    all_questions.extend(phonics_questions)
    
    # Vocabulary questions (t·ªëi ƒëa 4 c√¢u, nh∆∞ng ch·ªâ l·∫•y ƒë·ªß ƒë·ªÉ c√≥ 10 c√¢u t·ªïng)
    vocab_questions = create_vocabulary_questions(unit_data)
    all_questions.extend(vocab_questions)
    
    # Sentence questions (2-3 c√¢u)
    sentence_questions = create_sentence_questions(unit_data)
    all_questions.extend(sentence_questions)
    
    # ƒê·∫£m b·∫£o c√≥ ƒë√∫ng 10 c√¢u, kh√¥ng tr√πng l·∫∑p
    unique_questions = []
    seen_questions = set()
    for q in all_questions:
        question_key = q["question"]
        if question_key not in seen_questions:
            unique_questions.append(q)
            seen_questions.add(question_key)
            if len(unique_questions) >= 10:
                break
    
    # N·∫øu v·∫´n thi·∫øu, th√™m c√¢u h·ªèi b·ªï sung t·ª´ vocabulary
    while len(unique_questions) < 10:
        vocab_list = unit_data["vocabulary"]
        question_types_extra = [
            "Find the word:",
            "What is:",
            "Choose:",
            "Match:"
        ]
        for i, vocab in enumerate(vocab_list):
            if len(unique_questions) >= 10:
                break
            # T·∫°o c√¢u h·ªèi m·ªõi v·ªõi format ph√π h·ª£p l·ªõp 1 (KH√îNG d√πng "What does X mean?")
            question_type = question_types_extra[i % len(question_types_extra)]
            question_text = f"{question_type} '{vocab}'"
            if question_text not in seen_questions:
                distractors = get_distractor_words(vocab, 3)
                options = [vocab] + distractors[:3]
                random.shuffle(options)
                correct_idx = options.index(vocab)
                unique_questions.append({
                    "question": question_text,
                    "options": options,
                    "correct": correct_idx,
                    "explanation": f"Ti·∫øng Vi·ªát: '{vocab}' l√† t·ª´ ti·∫øng Anh ƒë√∫ng. English: '{vocab}' is the correct English word."
                })
                seen_questions.add(question_text)
    
    # Gi·ªõi h·∫°n ƒë√∫ng 10 c√¢u
    unique_questions = unique_questions[:10]
    
    # Ph√¢n b·ªï ƒë√°p √°n ƒë√∫ng
    unique_questions = assign_correct_answers(unique_questions, unit_data["answer_dist"])
    
    # Convert sang format JSON
    json_questions = []
    for i, q in enumerate(unique_questions):
        json_questions.append({
            "id": f"q{i + 1}",
            "type": "multiple-choice",
            "question": q["question"],
            "options": q["options"],
            "correctAnswer": q["correct"],
            "explanation": q["explanation"],
            "imageUrl": None
        })
    
    # T·∫°o structure JSON
    week_data = {
        "week": week_num,
        "subject": "english",
        "grade": 1,
        "bookSeries": "ket-noi-tri-thuc",
        "lessons": [
            {
                "id": f"lesson-{week_num}",
                "title": unit_data["title"],
                "duration": 10,
                "questions": json_questions
            }
        ]
    }
    
    # Ghi file
    output_path = Path(output_dir) / f"week-{week_num}.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(week_data, f, ensure_ascii=False, indent=2)
    
    # Verify ph√¢n b·ªï ƒë√°p √°n
    answer_counts = Counter(q["correctAnswer"] for q in json_questions)
    print(f"‚úÖ Created: week-{week_num}.json | Answers: A={answer_counts[0]}, B={answer_counts[1]}, C={answer_counts[2]}, D={answer_counts[3]}")
    
    return week_data

def main():
    # Set random seed ƒë·ªÉ c√≥ th·ªÉ reproduce
    random.seed(42)
    
    # ƒê∆∞·ªùng d·∫´n output
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    output_dir = project_root / "src" / "data" / "questions" / "ket-noi-tri-thuc" / "grade-1" / "english"
    
    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("üöÄ B·∫Øt ƒë·∫ßu t·∫°o b·ªô ƒë·ªÅ ti·∫øng Anh l·ªõp 1 - 16 ch·∫∑ng th·ª≠ th√°ch...")
    print(f"üìÅ Output directory: {output_dir}\n")
    
    # T·∫°o 16 files
    for unit_data in UNITS_DATA:
        create_week_file(unit_data, output_dir)
    
    print(f"\n‚úÖ Ho√†n th√†nh! ƒê√£ t·∫°o {len(UNITS_DATA)} files trong: {output_dir}")

if __name__ == "__main__":
    main()
